<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.3">Jekyll</generator><link href="https://blog.rifhanakram.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.rifhanakram.com/" rel="alternate" type="text/html" /><updated>2025-09-16T01:01:38+05:30</updated><id>https://blog.rifhanakram.com/feed.xml</id><title type="html">Scribbles by Rifhan</title><subtitle>Scribbles by Rifhan is a personal blog</subtitle><author><name>Rifhan Akram</name></author><entry><title type="html">IAM What I AM: Locking Down Your AWS Kingdom üëë</title><link href="https://blog.rifhanakram.com/posts/IAM-what-IAM-secure-your-aws-kingdom/" rel="alternate" type="text/html" title="IAM What I AM: Locking Down Your AWS Kingdom üëë" /><published>2025-09-16T00:00:00+05:30</published><updated>2025-09-16T00:00:00+05:30</updated><id>https://blog.rifhanakram.com/posts/IAM-what-IAM-secure-your-aws-kingdom</id><content type="html" xml:base="https://blog.rifhanakram.com/posts/IAM-what-IAM-secure-your-aws-kingdom/">&lt;h1 id=&quot;iam-what-i-am-locking-down-your-aws-kingdom-&quot;&gt;IAM What I AM: Locking Down Your AWS Kingdom üëë&lt;/h1&gt;

&lt;p&gt;Welcome to the startup grind! You‚Äôre moving fast, building amazing things, and probably deploying to AWS multiple times a day. üöÄ In this whirlwind of innovation, it‚Äôs easy to let security best practices slip. But here‚Äôs the thing: getting your &lt;strong&gt;Identity and Access Management (IAM)&lt;/strong&gt; right from day one is one of the most critical things you can do. Think of IAM as the bouncer for your entire AWS environment‚Äîit decides who gets in and what they can do.&lt;/p&gt;

&lt;p&gt;Getting it wrong can be catastrophic, but getting it right is straightforward. Here are seven foundational best practices to lock down your AWS organization and build a secure, scalable foundation.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;1-practice-safe-clicks-enable-mfa-everywhere&quot;&gt;1. Practice Safe Clicks: Enable MFA Everywhere&lt;/h3&gt;

&lt;p&gt;If you do only one thing from this list, make it this one. &lt;strong&gt;Multi-Factor Authentication (MFA)&lt;/strong&gt; adds a crucial second layer of security. A password can be stolen, but a physical token or an app on your phone is much harder to compromise.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;The Golden Rule:&lt;/strong&gt; Your &lt;strong&gt;root account&lt;/strong&gt;‚Äîthe email address you used to create your AWS account‚Äîis the superuser with the keys to the entire kingdom. &lt;strong&gt;It must have MFA enabled.&lt;/strong&gt; No exceptions.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Don‚Äôt Stop at Root:&lt;/strong&gt; Every single IAM user in your organization, from the CEO to the intern, should also have MFA enforced. This dramatically reduces the risk of an account takeover from a compromised password.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;2-your-password-isnt-a-pets-name-enforce-a-strong-policy&quot;&gt;2. Your Password Isn‚Äôt a Pet‚Äôs Name: Enforce a Strong Policy&lt;/h3&gt;

&lt;p&gt;Default password settings are often too permissive. You can, and should, set a strong password policy for all your IAM users to prevent weak or easily guessable passwords.&lt;/p&gt;

&lt;p&gt;In the IAM dashboard, you can configure a policy that requires:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Minimum Length:&lt;/strong&gt; At least 12-14 characters.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Character Complexity:&lt;/strong&gt; A mix of uppercase letters, lowercase letters, numbers, and symbols (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;!@#$%&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Password Expiration:&lt;/strong&gt; Require users to change their passwords periodically (e.g., every 90 days).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Prevent Reuse:&lt;/strong&gt; Stop users from recycling their last few passwords.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;3-dont-leave-your-keys-lying-around-rotate-access-keys&quot;&gt;3. Don‚Äôt Leave Your Keys Lying Around: Rotate Access Keys&lt;/h3&gt;

&lt;p&gt;Your developers use &lt;strong&gt;access keys&lt;/strong&gt; (an Access Key ID and a Secret Access Key) for programmatic access to AWS via the CLI, SDKs, and other tools. These long-lived credentials are powerful and, if leaked, pose a massive security risk.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Establish a Rotation Policy:&lt;/strong&gt; Just like passwords, access keys should be rotated regularly. A &lt;strong&gt;90-day rotation&lt;/strong&gt; is a strong industry standard.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Delete Unused Keys:&lt;/strong&gt; If a key hasn‚Äôt been used in 30 or 60 days, it‚Äôs likely not needed. Use IAM Access Analyzer to identify these unused keys and delete them to shrink your security footprint.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Regular rotation minimizes the window of opportunity for an attacker to use a compromised key.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;4-break-glass-in-case-of-emergency-the-root-user&quot;&gt;4. Break Glass in Case of Emergency: The Root User&lt;/h3&gt;

&lt;p&gt;The root user has god-mode privileges. It can do anything, including deleting all your resources and closing the account. For this reason, you should &lt;strong&gt;never&lt;/strong&gt; use it for your daily work.&lt;/p&gt;

&lt;p&gt;Here‚Äôs the process:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Enable MFA on the root user (see point #1).&lt;/li&gt;
  &lt;li&gt;Create a separate &lt;strong&gt;IAM user&lt;/strong&gt; for yourself and grant it administrative privileges by attaching the AWS-managed &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AdministratorAccess&lt;/code&gt; policy.&lt;/li&gt;
  &lt;li&gt;Log out of the root user and log back in with your new admin IAM user.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lock away your root user credentials&lt;/strong&gt; in a secure place.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Only use the root user for a very small, specific set of tasks that require it, like changing your AWS Support plan.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;5-work-on-a-need-to-know-basis-the-principle-of-least-privilege&quot;&gt;5. Work on a ‚ÄúNeed-to-Know‚Äù Basis: The Principle of Least Privilege&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;principle of least privilege&lt;/strong&gt; is simple: only grant the &lt;em&gt;minimum permissions&lt;/em&gt; necessary for a user to perform their job. Don‚Äôt give every developer admin access ‚Äújust in case.‚Äù This limits the ‚Äúblast radius‚Äù if an account is ever compromised.&lt;/p&gt;

&lt;p&gt;The best way to manage this is with &lt;strong&gt;IAM Groups and Policies&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Don‚Äôt attach policies directly to users.&lt;/strong&gt; It becomes a nightmare to manage.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Create Groups based on roles:&lt;/strong&gt; Create groups like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Developers&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;DataScientists&lt;/code&gt;, or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ReadOnlyUsers&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Attach policies to the Groups:&lt;/strong&gt; Attach finely-tuned IAM policies to each group that grant only the necessary permissions for that role.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Add users to the Groups:&lt;/strong&gt; When a new developer joins, simply add them to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Developers&lt;/code&gt; group.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;6-let-your-services-do-the-talking-use-iam-roles&quot;&gt;6. Let Your Services Do the Talking: Use IAM Roles&lt;/h3&gt;

&lt;p&gt;Your applications running on EC2, Lambda, or ECS often need to access other AWS services (like S3 or DynamoDB). The worst way to grant this access is by hardcoding access keys into your code or configuration files.&lt;/p&gt;

&lt;p&gt;The secure, modern approach is to use &lt;strong&gt;IAM Roles for Services&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Create an IAM Role that has the specific permissions your application needs (e.g., ‚Äúallow read/write access to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;my-cool-bucket&lt;/code&gt;‚Äù).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Attach that role&lt;/strong&gt; to the AWS service where your code is running (e.g., launch your EC2 instance or configure your Lambda function with this role).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The service then automatically receives temporary, rotated credentials. There are &lt;strong&gt;no static keys&lt;/strong&gt; to steal from your code or your servers. This is a non-negotiable best practice.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;7-dont-put-all-your-eggs-in-one-basket-a-multi-account-strategy&quot;&gt;7. Don‚Äôt Put All Your Eggs in One Basket: A Multi-Account Strategy&lt;/h3&gt;

&lt;p&gt;As you grow, you‚Äôll want to isolate your different environments. A bug in development shouldn‚Äôt be able to take down production. The best practice here is to use &lt;strong&gt;AWS Organizations&lt;/strong&gt; to create separate AWS accounts for different workloads (e.g., Dev, Staging, Production).&lt;/p&gt;

&lt;p&gt;Crucially, you should &lt;strong&gt;centralize user management&lt;/strong&gt; in one main account:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Your IAM users exist &lt;strong&gt;only&lt;/strong&gt; in the main management account.&lt;/li&gt;
  &lt;li&gt;In your Production account, you create &lt;strong&gt;IAM Roles&lt;/strong&gt; (e.g., &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Production-Admin-Role&lt;/code&gt;).&lt;/li&gt;
  &lt;li&gt;Your users in the main account use the &lt;strong&gt;Switch Role&lt;/strong&gt; feature to temporarily gain access to the Production account.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This provides a powerful security boundary and a crystal-clear audit trail, all managed from a single location.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;your-secure-foundation&quot;&gt;Your Secure Foundation&lt;/h3&gt;

&lt;p&gt;Building a startup is a marathon, not a sprint. Taking a few hours now to implement these seven IAM practices will save you from major security headaches down the road and build a secure, professional-grade AWS environment that can scale with your success.&lt;/p&gt;</content><author><name>Rifhan Akram</name></author><category term="tech" /><summary type="html">IAM What I AM: Locking Down Your AWS Kingdom üëë</summary></entry><entry><title type="html">Lessons From ER To The Software World</title><link href="https://blog.rifhanakram.com/posts/lessons-from-er-to-software-world/" rel="alternate" type="text/html" title="Lessons From ER To The Software World" /><published>2025-04-14T00:00:00+05:30</published><updated>2025-04-14T00:00:00+05:30</updated><id>https://blog.rifhanakram.com/posts/lessons-from-er-to-software-world</id><content type="html" xml:base="https://blog.rifhanakram.com/posts/lessons-from-er-to-software-world/">&lt;p&gt;What can software engineers learn from emergency rooms? In this article, I explore how the principles of ER operations‚Äîfrom triaging and handling surges to conducting blameless postmortems‚Äîcan be applied to software incident response. Drawing parallels between medical emergencies and software incidents, I discuss the importance of proper logging, structured incident response playbooks, and continuous improvement through postmortems. The article provides practical insights for teams of any size to build more reliable software systems using lessons from emergency medicine.&lt;/p&gt;

&lt;p&gt;Read the full article on &lt;a href=&quot;https://engineering.corzent.com/when-things-go-wrong-lessons-from-er-emergency-room-to-the-software-world-9a28881c3b02&quot;&gt;Corzent‚Äôs Engineering Blog&lt;/a&gt;.&lt;/p&gt;</content><author><name>Rifhan Akram</name></author><category term="tech" /><summary type="html">What can software engineers learn from emergency rooms? In this article, I explore how the principles of ER operations‚Äîfrom triaging and handling surges to conducting blameless postmortems‚Äîcan be applied to software incident response. Drawing parallels between medical emergencies and software incidents, I discuss the importance of proper logging, structured incident response playbooks, and continuous improvement through postmortems. The article provides practical insights for teams of any size to build more reliable software systems using lessons from emergency medicine.</summary></entry><entry><title type="html">UUIDs vs ULIDs For Better Write Performance At Scale</title><link href="https://blog.rifhanakram.com/posts/ulids-vs-uuids-for-better-write-perf/" rel="alternate" type="text/html" title="UUIDs vs ULIDs For Better Write Performance At Scale" /><published>2023-01-14T00:00:00+05:30</published><updated>2023-01-14T00:00:00+05:30</updated><id>https://blog.rifhanakram.com/posts/ulids-vs-uuids-for-better-write-perf</id><content type="html" xml:base="https://blog.rifhanakram.com/posts/ulids-vs-uuids-for-better-write-perf/">&lt;h1 id=&quot;uuids-vs-ulids-for-better-write-performance-at-scale&quot;&gt;UUIDs vs ULIDs For Better Write Performance At Scale&lt;/h1&gt;

&lt;p&gt;In this article, we will be discussing the usage of keys as unique identifiers in a distributed relational database setup and their impact on write performance.&lt;/p&gt;

&lt;p&gt;The use of auto-incremented, non-repeating, sorted integers has been a common practice for defining primary keys in relational databases. This type of key has been successful because it satisfies the two most crucial indexing requirements.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;They are unique, so they can be uniquely identified.&lt;/li&gt;
  &lt;li&gt;They are ordered and sortable, so they can be efficiently indexed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;When the database is a monolithic entity, this kind of key is ideal. However, as soon as we decide to scale and move to a distributed setup this is no longer unique, this is because now multiple entities start generating auto-incremented numbers.&lt;/p&gt;

&lt;h2 id=&quot;impact-on-clustered-indexes-during-writes&quot;&gt;Impact on Clustered Indexes During Writes&lt;/h2&gt;

&lt;p&gt;Before we move on to discuss alternatives to auto-incremented integers as unique identifiers, let‚Äôs try to understand how indexes are impacted when relational databases write new data.&lt;/p&gt;

&lt;p&gt;Clustered indexes are typically represented in a b-tree data structure. They have several benefits that make them well-suited for usage in clustered indexes.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Efficient at searching for data: B-trees are designed to be efficient at searching for data, even in large datasets. They use a hierarchical structure that allows for fast traversal of the data, reducing the number of disk I/O operations required to find a specific value.&lt;/li&gt;
  &lt;li&gt;B-trees are balanced: B-trees are self-balancing data structures, which means they maintain a balanced tree structure even when data is inserted or deleted. This helps to ensure that the height of the tree remains relatively constant, which improves performance and reduces the risk of data becoming inaccessible.&lt;/li&gt;
  &lt;li&gt;B-trees support range queries: B-trees can support range queries which means they can be used to efficiently find all the values that fall within a specified range. This is useful in scenarios where you need to find all the records that fall within a certain range of values for a particular column.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In most cases in relational databases, it is allowed to have only 1 clustered index per table, this is because the physical organization of the data is controlled by the clustered index(by the column(s) the index is created, typically the primary key column).&lt;/p&gt;

&lt;p&gt;In MSSQL when writing data to a table the DBMS includes logical and physical writes. A logical write is when data is modified in a page in the buffer cache and marked as dirty. A physical write is when a dirty page is written from the buffer cache to the disk. Since logical writes are not immediately written to disk there can be more than one logical write to a page in the buffer cache as long as the record is intended to be written on that page(determined by the clustered index).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/sql-writes.png&quot; alt=&quot;sql-writes.png&quot; /&gt;
&lt;em&gt;Reference - &lt;a href=&quot;https://learn.microsoft.com/en-us/sql/relational-databases/writing-pages?view=sql-server-ver16&quot;&gt;Writing Pages - SQL Server | Microsoft Learn&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The DBMS must first determine the correct page to store the new row of data based on the clustered index. To do this, it typically performs a binary search on the index to identify the correct page, once the page is identified it needs to read the page from the disk into the buffer cache, this is only required if the page is not present in the buffer cache.&lt;/p&gt;

&lt;p&gt;If the clustered index key adheres to the indexing requirements discussed above then subsequent writes will not require reading pages from the physical disk as in most cases they will be available in the buffer cache due to a previous write in near time reading it into the buffer cache.&lt;/p&gt;

&lt;p&gt;As soon as you start using a column that is not ordered(during generation) for a clustered index; It would mean that the data stored in the table requires additional work to be organized in a logical order, which would result in poor write performance.&lt;/p&gt;

&lt;h2 id=&quot;alternative-unique-identifiers-in-a-distributed-environment&quot;&gt;Alternative Unique Identifiers In a Distributed Environment&lt;/h2&gt;

&lt;h3 id=&quot;universally-unique-identifier-uuid&quot;&gt;Universally Unique Identifier (UUID)&lt;/h3&gt;

&lt;p&gt;UUIDs are 128-bit long strings that can guarantee
uniqueness across space and time. They are widely used to uniquely identify resources. There are several versions of UUIDs, each with a slightly different format. The most generally used UUID version is 4.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/uuid.png&quot; alt=&quot;uuid.png&quot; /&gt;
&lt;em&gt;128 bit UUIDV4 string&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;A more detailed explanation of UUID can be found in &lt;a href=&quot;https://www.ietf.org/rfc/rfc4122.txt&quot;&gt;RFC 4122&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;UUID in a distributed setup allows uniqueness but they are not so good for write performance and here is why;&lt;/p&gt;

&lt;p&gt;UUIDs are randomized strings(in most versions) that have no particular order in a generation. When you use them for a clustered index column they need to be ordered and stored. Since they are not ordered(naturally during generation) it requires more I/O to store them on the correct page, this could result in bad write performance in large tables and it could lead to issues like &lt;a href=&quot;https://learn.microsoft.com/en-us/sql/relational-databases/indexes/reorganize-and-rebuild-indexes?view=sql-server-ver16&quot;&gt;index fragmentation&lt;/a&gt;  as the data pages may not be in contiguous order.&lt;/p&gt;

&lt;h3 id=&quot;universally-unique-lexicographically-sortable-identifier-ulid&quot;&gt;Universally Unique Lexicographically Sortable Identifier (ULID)&lt;/h3&gt;

&lt;p&gt;As the title suggests ULIDs are universally unique yet lexicographically sortable identifiers, this is mainly why it is better in write performance at scale compared to UUIDs. ULIDs are a relatively new form of identifiers and still lack widespread native support.&lt;/p&gt;

&lt;p&gt;ULID is generated in 2 components,&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Timestamp - 48-bit, integer with the UNIX-time in milliseconds&lt;/li&gt;
  &lt;li&gt;Randomness - 80-bit random string&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In total, they are a 128-bit long unique yet lexicographically sortable string. ULID is encoded using a combination of binary and base32 characters which results in a more compact 26-character format compared to the 36 characters generated by UUID v4.&lt;/p&gt;

&lt;p&gt;More details about ULID can be found in its &lt;a href=&quot;[ulid/spec: The canonical spec for ulid (github.com)](https://github.com/ulid/spec)&quot;&gt;specification document&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In general, we can conclude that ULIDs tend to have the upper hand in write performance( in most cases ) compared to UUIDs, specifically due to the lexicographically sortable nature of ULID.&lt;/p&gt;

&lt;p&gt;Thank you for reading this article. I hope to see you at the next one.&lt;/p&gt;</content><author><name>Rifhan Akram</name></author><category term="tech" /><summary type="html">UUIDs vs ULIDs For Better Write Performance At Scale</summary></entry><entry><title type="html">Automated CI/CD for Monorepo‚Äôs</title><link href="https://blog.rifhanakram.com/posts/jenkins-pipeline-monorepo/" rel="alternate" type="text/html" title="Automated CI/CD for Monorepo‚Äôs" /><published>2020-10-27T00:00:00+05:30</published><updated>2020-10-27T00:00:00+05:30</updated><id>https://blog.rifhanakram.com/posts/jenkins-pipeline-monorepo</id><content type="html" xml:base="https://blog.rifhanakram.com/posts/jenkins-pipeline-monorepo/">&lt;p&gt;Monorepo is an approach in managing source code under a product, team or company within a single repo as oppose to multi-repo where a single product/application is contained within its own git repository.&lt;/p&gt;

&lt;p&gt;The two approaches has its own pro‚Äôs and con‚Äôs. In this article i will not be discussing on what is the best approach as it entirely matters on the context we work, rather i will walk the through the challenges of Automated CI/CD with &lt;strong&gt;mono-repo&lt;/strong&gt; and how we can over come them with structure and some magic with &lt;a href=&quot;https://www.jenkins.io/doc/book/pipeline/&quot;&gt;Jenkins Pipeline&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;challenges&quot;&gt;Challenges&lt;/h2&gt;

&lt;p&gt;Due to the nature of multiple applications residing in a single repo it is not trivial to setup a CI/CD job that detects changes and executes only the &lt;strong&gt;impacted applications related CI/CD job&lt;/strong&gt;. Some of the steps that contain in a typical pipeline are,&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Building the code&lt;/li&gt;
  &lt;li&gt;Running automated tests&lt;/li&gt;
  &lt;li&gt;Creating and versioning a deployable artifact&lt;/li&gt;
  &lt;li&gt;Deploying that artifact&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lets look at how we can tackle this problem with Jenkins.&lt;/p&gt;

&lt;h2 id=&quot;some-jenkins-magic&quot;&gt;Some Jenkins Magic&lt;/h2&gt;
&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;sample structure in a mono-repo setup with jenkins pipeline&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;.
‚îú‚îÄ‚îÄ src                                 
    ‚îú‚îÄ‚îÄ react-app
        ‚îú‚îÄ‚îÄ Jenkinsfile     
    ‚îú‚îÄ‚îÄ node-app
        ‚îú‚îÄ‚îÄ Jenkinsfile                                                               
‚îî‚îÄ‚îÄ Jenkinsfile                 # main jenkinsfile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;If we consider a structure like above, with jenkins we could setup the main Jenkinsfile in the root of the repository as a &lt;a href=&quot;https://www.jenkins.io/doc/tutorials/build-a-multibranch-pipeline-project/&quot;&gt;multi-branch jenkins job&lt;/a&gt;. This job can be connected with your remote repository such that it triggers via a webhook when a PR is merged to your mainline branch. You can get creative with the triggers depending on the workflow your team follows.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;A stage inside the main Jenkinsfile is shown below&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;stage(&apos;Execute Jobs&apos;) {
    failFast false
    parallel {
        stage(&apos;react-app ci&apos;) {
            when {
                changeset &quot;src/react-app/**&quot;
            }
            steps {
                build job: &quot;react-app-job&quot;, parameters: [string(name: &apos;branch_name&apos;, value: env.BRANCH_NAME)]
            }
        }
        stage(&apos;node-app ci&apos;) {
            when {
                changeset &quot;src/node-app/**&quot;
            }
            steps {
                build job: &quot;node-app-job&quot;, parameters: [string(name: &apos;branch_name&apos;, value: env.BRANCH_NAME)]
            }
        }
    }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the above example the &lt;strong&gt;changeset&lt;/strong&gt; condition walks through the git changelog for that particular change and checks if there is any change within the given path. If a change is detected then the &lt;strong&gt;build job&lt;/strong&gt; step executes the related jenkins job.&lt;/p&gt;

&lt;p&gt;Note - &lt;em&gt;&lt;strong&gt;failFast&lt;/strong&gt; is set to false to avoid failure of the entire pipeline if one job fails.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Once we have this setup we can go about and setup separate pipeline jobs for each application in the repository.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Below is an example on how the main multi-branch job will look in Jenkins&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/jenkins-multi-main.png&quot; alt=&quot;jenkins-multi-main.png&quot; /&gt;
In the above image the multi-branch job has executed when a change has been pushed to the master branch. When we navigate into the master branch execution we can see the pipeline as shown below,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/static/img/jenkins-multi-stage-view.png&quot; alt=&quot;jenkins-multi-stage-view.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the stage view we can see that build #9 contains changes only for 1 application and build #10 contains changes for both.&lt;/p&gt;

&lt;p&gt;This is an awesome and quick setup with Jenkins for a monorepo. I‚Äôm a big fan of Jenkins due to its flexibility and extensibility specially with declarative &lt;a href=&quot;https://www.jenkins.io/doc/book/pipeline/&quot;&gt;Jenkins Pipeline&lt;/a&gt;.&lt;/p&gt;</content><author><name>Rifhan Akram</name></author><category term="tech" /><summary type="html">Monorepo is an approach in managing source code under a product, team or company within a single repo as oppose to multi-repo where a single product/application is contained within its own git repository.</summary></entry></feed>